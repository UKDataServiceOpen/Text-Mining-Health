{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UKDS Logo](images/UKDS_Logos_Col_Grey_300dpi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Foot and Mouth: Pre-processing (retrieval, segmentation, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Retrieval\" data-toc-modified-id=\"Retrieval-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Retrieval</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-the-.csv-exists-and-is-where-you-think-it-is\" data-toc-modified-id=\"Check-the-.csv-exists-and-is-where-you-think-it-is-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Check the .csv exists and is where you think it is</a></span></li></ul></li><li><span><a href=\"#Get-the-data-in-order\" data-toc-modified-id=\"Get-the-data-in-order-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get the data in order</a></span><ul class=\"toc-item\"><li><span><a href=\"#Rename-columns\" data-toc-modified-id=\"Rename-columns-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Rename columns</a></span></li><li><span><a href=\"#Adding-Occupation-Column\" data-toc-modified-id=\"Adding-Occupation-Column-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Adding Occupation Column</a></span></li><li><span><a href=\"#Preparing-to-split-columns\" data-toc-modified-id=\"Preparing-to-split-columns-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Preparing to split columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pt1.-Where-to-split-the-Dataframe-Rows?\" data-toc-modified-id=\"Pt1.-Where-to-split-the-Dataframe-Rows?-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Pt1. Where to split the Dataframe Rows?</a></span></li><li><span><a href=\"#Pt.-2---ACTUALLY-splitting-the-dataframe-into-2-(3!)-parts\" data-toc-modified-id=\"Pt.-2---ACTUALLY-splitting-the-dataframe-into-2-(3!)-parts-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Pt. 2 - ACTUALLY splitting the dataframe into 2 (3!) parts</a></span></li></ul></li></ul></li><li><span><a href=\"#Regular-conditional-filtering-vs-Boolean-masking\" data-toc-modified-id=\"Regular-conditional-filtering-vs-Boolean-masking-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Regular conditional filtering vs Boolean masking</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tilde-operator-+-boolean-masking-for-counting-Occupation-instances\" data-toc-modified-id=\"Tilde-operator-+-boolean-masking-for-counting-Occupation-instances-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tilde operator + boolean masking for counting Occupation instances</a></span></li></ul></li><li><span><a href=\"#Pre-Processing-Summary\" data-toc-modified-id=\"Pre-Processing-Summary-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Pre-Processing Summary</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in text-mining, or any form of data-mining, is retrieving a data set to work with. Within text-mining, or any language analysis context, one data set is usually referred to as 'a corpus' while multiple data sets are referred to as 'corpora'. 'Corpus' is a latin-root word and therefore has a funny plural. \n",
    "\n",
    "For text-mining, a corpus can be:\n",
    "- a set of tweets, \n",
    "- the full text of an 18th centrury novel,\n",
    "- the contents of a page in the dictionary, \n",
    "- minutes of local council meetings, \n",
    "- random gibberish letters and numbers, or\n",
    "- just about anything else in text format. \n",
    "\n",
    "Instead, for the purposes of this notebook, we will be retrieving a .csv file that we created in a different notebook (importing_multiple_rtf.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the .csv exists and is where you think it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. One of the files in ./data is... foot_mouth_original.xls\n",
      "2. One of the files in ./data is... text.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It is good practice to always start by importing the modules and packages you will need. \n",
    "\n",
    "import os                         # os is a module for navigating your machine (e.g., file directories).\n",
    "import pandas as pd\n",
    "\n",
    "# List all of the files in the \"data\" folder that is provided to you\n",
    "print(\"\")\n",
    "for file in os.listdir(\"./data/foot_mouth\"):\n",
    "   print(\"2. One of the files in ./data is...\", file)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "Great! The file we want to use is available, so now we need to load that .csv file as a python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                0  \\\n",
      "0           0  5407diary02.rtf   \n",
      "1           1  5407diary03.rtf   \n",
      "2           2  5407diary07.rtf   \n",
      "3           3  5407diary08.rtf   \n",
      "4           4  5407diary09.rtf   \n",
      "5           5  5407diary10.rtf   \n",
      "6           6  5407diary13.rtf   \n",
      "7           7  5407diary14.rtf   \n",
      "8           8  5407diary15.rtf   \n",
      "9           9  5407diary16.rtf   \n",
      "\n",
      "                                                   1  \n",
      "0  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
      "1  Information about diarist\\nDate of birth: 1966...  \n",
      "2  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
      "3  Information about diarist\\nDate of birth: 1963...  \n",
      "4  Information about diarist\\nDate of birth: 1981...  \n",
      "5  Information about diarist\\nDate of birth: 1937...  \n",
      "6  Information about diarist\\nDate of birth: 1947...  \n",
      "7  \\nInformation about diarist\\nDate of birth: 19...  \n",
      "8  Information about diarist\\nDate of birth: 1949...  \n",
      "9  \\nInformation about diarist\\nDate of birth: 19...  \n"
     ]
    }
   ],
   "source": [
    "foot_mouth_df = pd.read_csv ('../code/data/foot_mouth/text.csv')    # loads the specific file into a python-only object\n",
    "print (foot_mouth_df[:10])                                          # prints the 1st 10 rows to get a sense of its contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "Right. We have three columns, one is a number, one is the name of the original .rtf file that the text came from, and one is the text. \n",
    "\n",
    "Looks a bit messy. \n",
    "\n",
    "Before we go further, it helps to know what kind of variable foot_mouth_df is. Run/Shift+Enter the next code block to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(foot_mouth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "This tells us that 'foot_mouth_df' is a pandas DataFrame. That is not a bad thing. \n",
    "\n",
    "Congratulations! We are done with the retreival portion of this process. The rest won't be quite so straightforward because next up... Accessing! This allows us to get individual rows, columns and/or cells to inspect, change, label, or split them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we can access any column, row or cell without using named labels. But it might be easier to give some of the things named labels. This makes more sense with columns - especially if we are going to split the columns into lots of other columns and it will be hard to keep track of what the numbered columns refer to. \n",
    "\n",
    "For now, lets keep working with the foot_mouth_df rather than any new variables you might have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                0  \\\n",
       "0           0  5407diary02.rtf   \n",
       "1           1  5407diary03.rtf   \n",
       "2           2  5407diary07.rtf   \n",
       "3           3  5407diary08.rtf   \n",
       "4           4  5407diary09.rtf   \n",
       "\n",
       "                                                   1  \n",
       "0  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
       "1  Information about diarist\\nDate of birth: 1966...  \n",
       "2  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
       "3  Information about diarist\\nDate of birth: 1963...  \n",
       "4  Information about diarist\\nDate of birth: 1981...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foot_mouth_df.head()        # name_of_dataframe.head() is an easy way to see the column names and 1st 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our columns have pretty stupid names. Let's change that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines the columns. It will overwrite whatever is already there for column names. \n",
    "# It will also owerwrite that weird \"unnamed:0\" thing in the first column that we had.  as is this case. )\n",
    "foot_mouth_df.columns = [\"Number\", \"Filename\", \"everything_else\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check and see if it worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number         Filename                                    everything_else\n",
       "0       0  5407diary02.rtf  \\n\\nInformation about diarist\\nDate of birth: ...\n",
       "1       1  5407diary03.rtf  Information about diarist\\nDate of birth: 1966...\n",
       "2       2  5407diary07.rtf  \\n\\nInformation about diarist\\nDate of birth: ...\n",
       "3       3  5407diary08.rtf  Information about diarist\\nDate of birth: 1963...\n",
       "4       4  5407diary09.rtf  Information about diarist\\nDate of birth: 1981..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foot_mouth_df.head()        # name_of_dataframe.head() is an easy way to see the column names and 1st 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Occupation Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off we will create a new Pandas Dataframe with an occupation column in it. This is what we will be doing the rest of the pre-processing on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_foot_mouth = foot_mouth_df.assign(Occupation = foot_mouth_df['everything_else'].str.extract(r'(\\w+\\s+\\d{1,2})'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's double-check that this didn't affect the original foot_mouth dataframe! (I will be using the original dataframe for processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number         Filename                                    everything_else\n",
       "0       0  5407diary02.rtf  \\n\\nInformation about diarist\\nDate of birth: ...\n",
       "1       1  5407diary03.rtf  Information about diarist\\nDate of birth: 1966...\n",
       "2       2  5407diary07.rtf  \\n\\nInformation about diarist\\nDate of birth: ...\n",
       "3       3  5407diary08.rtf  Information about diarist\\nDate of birth: 1963...\n",
       "4       4  5407diary09.rtf  Information about diarist\\nDate of birth: 1981..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foot_mouth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now how about we work on splitting that \"everything_else\" column in our Occupation dataframe more useful things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing to split columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pt1. Where to split the Dataframe Rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to actually splitting the \"everything else\" column, let's just triple check that it is consistent all the way down. \n",
    "\n",
    "This is important because usually we split according to a specific position (like \"after the 10th character\" or after a specific delimiter (like \"after every comma\"). We don't actually know that we have either a position or delimiter to use that applies to all of the files.  \n",
    "\n",
    "\n",
    "We could look at *every* cell in the column of interest, or we could look at the first few and the last few and jump to some conclusions. Since we already know how to find the head, let's compare that head to the tail. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(foot_mouth_df.head())\n",
    "print(\" \")\n",
    "print(foot_mouth_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm. They are not all consistent. But there is a lot of consistency! The diary files seem to start with \"Information about diarist\" while the interview files start with \"date of interview\". \n",
    "\n",
    "It seems like we can't split the columns until we split this data frame into 2, one for diary files and one for interview files. How would you go about doing that? Steps to consider might include:\n",
    "* find the last row of the diary entries and the first row of the interview entries (using access rows and/or access cells)\n",
    "* save a new \"diary\" variable that contains all of the columns for all of the diary rows\n",
    "* save a new \"interview\" variable that contains all of the columns for all of the interview rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding where to split the columns\n",
    "\n",
    "foot_mouth_df.loc[:50] # Quick inspection to see where the splits should be put\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! So looks like there is a random extra type of file for 'Group Discussions' that we will also need to split up!\n",
    "\n",
    "But that's fine wont take much to split it - its just one extra line of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pt. 2 - ACTUALLY splitting the dataframe into 2 (3!) parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting variables that split up the DataFrame\n",
    "\n",
    "diary_file = oc_foot_mouth.loc[:39]     # Saving variable for all diary rows\n",
    "group_file = oc_foot_mouth.loc[40:45]   # Saving variables for all group interview rows\n",
    "interview_file = oc_foot_mouth.loc[46:] # Saving variable for all interview rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now quickly checking the type!\n",
    "\n",
    "type(diary_file)\n",
    "type(group_file)\n",
    "type(interview_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay and now to check the contents of these split dataframes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5407diary10.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1937...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5407diary13.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1947...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5407diary14.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5407diary15.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1949...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5407diary16.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5407diary17.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1936...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5407diary18.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5407diary19.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5407diary21.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5407diary22.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5407diary23.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5407diary24.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5407diary26.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5407diary27.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5407diary28.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number         Filename  \\\n",
       "0        0  5407diary02.rtf   \n",
       "1        1  5407diary03.rtf   \n",
       "2        2  5407diary07.rtf   \n",
       "3        3  5407diary08.rtf   \n",
       "4        4  5407diary09.rtf   \n",
       "5        5  5407diary10.rtf   \n",
       "6        6  5407diary13.rtf   \n",
       "7        7  5407diary14.rtf   \n",
       "8        8  5407diary15.rtf   \n",
       "9        9  5407diary16.rtf   \n",
       "10      10  5407diary17.rtf   \n",
       "11      11  5407diary18.rtf   \n",
       "12      12  5407diary19.rtf   \n",
       "13      13  5407diary21.rtf   \n",
       "14      14  5407diary22.rtf   \n",
       "15      15  5407diary23.rtf   \n",
       "16      16  5407diary24.rtf   \n",
       "17      17  5407diary26.rtf   \n",
       "18      18  5407diary27.rtf   \n",
       "19      19  5407diary28.rtf   \n",
       "\n",
       "                                      everything_else Occupation  \n",
       "0   \\n\\nInformation about diarist\\nDate of birth: ...    Group 6  \n",
       "1   Information about diarist\\nDate of birth: 1966...    Group 6  \n",
       "2   \\n\\nInformation about diarist\\nDate of birth: ...    Group 6  \n",
       "3   Information about diarist\\nDate of birth: 1963...    Group 6  \n",
       "4   Information about diarist\\nDate of birth: 1981...    Group 5  \n",
       "5   Information about diarist\\nDate of birth: 1937...    Group 5  \n",
       "6   Information about diarist\\nDate of birth: 1947...    Group 5  \n",
       "7   \\nInformation about diarist\\nDate of birth: 19...    Group 5  \n",
       "8   Information about diarist\\nDate of birth: 1949...    Group 5  \n",
       "9   \\nInformation about diarist\\nDate of birth: 19...    Group 5  \n",
       "10  Information about diarist\\nDate of birth: 1936...    Group 5  \n",
       "11  \\nInformation about diarist\\nDate of birth: 19...    Group 5  \n",
       "12  \\nInformation about diarist\\nDate of birth: 19...    Group 4  \n",
       "13  \\nInformation about diarist\\nDate of birth: 19...    Group 4  \n",
       "14  \\nInformation about diarist\\nDate of birth: 19...    Group 4  \n",
       "15  \\nInformation about diarist\\nDate of birth: 19...    Group 4  \n",
       "16  \\nInformation about diarist\\nDate of birth: 19...    Group 4  \n",
       "17  \\nInformation about diarist\\nDate of birth: 19...    Group 4  \n",
       "18  \\nInformation about diarist\\nDate of birth: 19...    Group 3  \n",
       "19  \\nInformation about diarist\\nDate of birth: 19...    Group 3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary_file[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>5407fg01.rtf</td>\n",
       "      <td>\\nGroups Discussion with Members of  Farmers F...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>5407fg02.rtf</td>\n",
       "      <td>Groups Discussion with Members of Small Busine...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>5407fg03.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Members of  Agricul...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>5407fg04.rtf</td>\n",
       "      <td>\\nNO AUDIO RECORDING\\n\\nGroups Discussion with...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>5407fg05.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Community Group of ...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number      Filename                                    everything_else  \\\n",
       "40      40  5407fg01.rtf  \\nGroups Discussion with Members of  Farmers F...   \n",
       "41      41  5407fg02.rtf  Groups Discussion with Members of Small Busine...   \n",
       "42      42  5407fg03.rtf  \\n\\nGroups Discussion with Members of  Agricul...   \n",
       "43      43  5407fg04.rtf  \\nNO AUDIO RECORDING\\n\\nGroups Discussion with...   \n",
       "44      44  5407fg05.rtf  \\n\\nGroups Discussion with Community Group of ...   \n",
       "\n",
       "   Occupation  \n",
       "40    Group 1  \n",
       "41    Group 2  \n",
       "42    Group 3  \n",
       "43    Group 4  \n",
       "44    Group 5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_file[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>5407int02.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>5407int03.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>5407int07.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>5407int08.rtf</td>\n",
       "      <td>\\nDate of Interview: 06/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>5407int09.rtf</td>\n",
       "      <td>\\nDate of Interview: 26/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>5407int10.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>5407int13.rtf</td>\n",
       "      <td>\\nDate of Interview: 19/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>5407int14.rtf</td>\n",
       "      <td>\\nDate of Interview: 25/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>5407int15.rtf</td>\n",
       "      <td>\\nDate of Interview: 25/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>5407int16.rtf</td>\n",
       "      <td>\\nDate of Interview: 07/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>5407int17.rtf</td>\n",
       "      <td>\\nDate of Interview: 12/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>5407int18.rtf</td>\n",
       "      <td>\\nDate of Interview: 07/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>5407int19.rtf</td>\n",
       "      <td>\\nDate of Interview: 23/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>5407int20.rtf</td>\n",
       "      <td>\\nDate of Interview: 26/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>5407int21.rtf</td>\n",
       "      <td>\\nDate of Interview: 26/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>5407int22.rtf</td>\n",
       "      <td>\\nDate of Interview: 27/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>5407int23.rtf</td>\n",
       "      <td>\\nDate of Interview: 21/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>5407int24.rtf</td>\n",
       "      <td>\\nDate of Interview: 21/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>5407int26.rtf</td>\n",
       "      <td>\\nDate of Interview: 01/03/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>5407int27.rtf</td>\n",
       "      <td>\\nDate of Interview: 04/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>5407int28.rtf</td>\n",
       "      <td>\\nDate of Interview: 04/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>5407int29.rtf</td>\n",
       "      <td>\\nDate of Interview: 04/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>5407int30.rtf</td>\n",
       "      <td>\\nDate of Interview: 13/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>5407int31.rtf</td>\n",
       "      <td>\\nDate of Interview: 04/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>5407int32.rtf</td>\n",
       "      <td>\\nDate of Interview: 04/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>5407int34.rtf</td>\n",
       "      <td>\\nDate of Interview: 15/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>5407int36.rtf</td>\n",
       "      <td>\\nDate of Interview: 04/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>5407int37.rtf</td>\n",
       "      <td>\\nDate of Interview: \\n\\nInformation about Pan...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>5407int39.rtf</td>\n",
       "      <td>\\nDate of Interview: 05/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>5407int40.rtf</td>\n",
       "      <td>\\nDate of Interview: 07/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>5407int41.rtf</td>\n",
       "      <td>\\nDate of Interview: 07/02/02\\n\\nInform...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>5407int42.rtf</td>\n",
       "      <td>\\nDate of Interview: 29/01/02\\n\\nInformation a...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>5407int43.rtf</td>\n",
       "      <td>\\nDate of Interview: 06/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>5407int44.rtf</td>\n",
       "      <td>\\nDate of Interview: 26/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>5407int47.rtf</td>\n",
       "      <td>\\nDate of Interview: 17/01/02\\n\\nInformation a...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>5407int48.rtf</td>\n",
       "      <td>\\nDate of Interview: 17/01/02\\n\\nInformation a...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>5407int49.rtf</td>\n",
       "      <td>\\nDate of Interview: 22/01/02\\n\\nInformation a...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>5407int52.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/01/02\\n\\nInformation a...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>5407int53.rtf</td>\n",
       "      <td>\\nDate of Interview: 21/01/02\\n\\nInformation a...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>5407int54.rtf</td>\n",
       "      <td>\\nDate of Interview: 17/01/02\\n\\nInformation a...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>5407int55.rtf</td>\n",
       "      <td>\\nDate of Interview: 27/02/02\\n\\nInformation a...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number       Filename                                    everything_else  \\\n",
       "46      46  5407int02.rtf  \\nDate of Interview: 14/03/02\\n\\nInformation a...   \n",
       "47      47  5407int03.rtf  \\nDate of Interview: 08/03/02\\n\\nInformation a...   \n",
       "48      48  5407int07.rtf  \\nDate of Interview: 14/03/02\\n\\nInformation a...   \n",
       "49      49  5407int08.rtf  \\nDate of Interview: 06/03/02\\n\\nInformation a...   \n",
       "50      50  5407int09.rtf  \\nDate of Interview: 26/02/02\\n\\nInformation a...   \n",
       "51      51  5407int10.rtf  \\nDate of Interview: 08/03/02\\n\\nInformation a...   \n",
       "52      52  5407int13.rtf  \\nDate of Interview: 19/03/02\\n\\nInformation a...   \n",
       "53      53  5407int14.rtf  \\nDate of Interview: 25/02/02\\n\\nInformation a...   \n",
       "54      54  5407int15.rtf  \\nDate of Interview: 25/02/02\\n\\nInformation a...   \n",
       "55      55  5407int16.rtf  \\nDate of Interview: 07/03/02\\n\\nInformation a...   \n",
       "56      56  5407int17.rtf  \\nDate of Interview: 12/03/02\\n\\nInformation a...   \n",
       "57      57  5407int18.rtf  \\nDate of Interview: 07/03/02\\n\\nInformation a...   \n",
       "58      58  5407int19.rtf  \\nDate of Interview: 23/02/02\\n\\nInformation a...   \n",
       "59      59  5407int20.rtf  \\nDate of Interview: 26/02/02\\n\\nInformation a...   \n",
       "60      60  5407int21.rtf  \\nDate of Interview: 26/02/02\\n\\nInformation a...   \n",
       "61      61  5407int22.rtf  \\nDate of Interview: 27/02/02\\n\\nInformation a...   \n",
       "62      62  5407int23.rtf  \\nDate of Interview: 21/02/02\\n\\nInformation a...   \n",
       "63      63  5407int24.rtf  \\nDate of Interview: 21/02/02\\n\\nInformation a...   \n",
       "64      64  5407int26.rtf  \\nDate of Interview: 01/03/02\\n\\nInformation a...   \n",
       "65      65  5407int27.rtf  \\nDate of Interview: 04/02/02\\n\\nInformation a...   \n",
       "66      66  5407int28.rtf  \\nDate of Interview: 04/02/02\\n\\nInformation a...   \n",
       "67      67  5407int29.rtf  \\nDate of Interview: 04/02/02\\n\\nInformation a...   \n",
       "68      68  5407int30.rtf  \\nDate of Interview: 13/02/02\\n\\nInformation a...   \n",
       "69      69  5407int31.rtf  \\nDate of Interview: 04/02/02\\n\\nInformation a...   \n",
       "70      70  5407int32.rtf  \\nDate of Interview: 04/02/02\\n\\nInformation a...   \n",
       "71      71  5407int34.rtf  \\nDate of Interview: 15/02/02\\n\\nInformation a...   \n",
       "72      72  5407int36.rtf  \\nDate of Interview: 04/02/02\\n\\nInformation a...   \n",
       "73      73  5407int37.rtf  \\nDate of Interview: \\n\\nInformation about Pan...   \n",
       "74      74  5407int39.rtf  \\nDate of Interview: 05/02/02\\n\\nInformation a...   \n",
       "75      75  5407int40.rtf  \\nDate of Interview: 07/02/02\\n\\nInformation a...   \n",
       "76      76  5407int41.rtf         \\nDate of Interview: 07/02/02\\n\\nInform...   \n",
       "77      77  5407int42.rtf  \\nDate of Interview: 29/01/02\\n\\nInformation a...   \n",
       "78      78  5407int43.rtf  \\nDate of Interview: 06/02/02\\n\\nInformation a...   \n",
       "79      79  5407int44.rtf  \\nDate of Interview: 26/02/02\\n\\nInformation a...   \n",
       "80      80  5407int47.rtf  \\nDate of Interview: 17/01/02\\n\\nInformation a...   \n",
       "81      81  5407int48.rtf  \\nDate of Interview: 17/01/02\\n\\nInformation a...   \n",
       "82      82  5407int49.rtf  \\nDate of Interview: 22/01/02\\n\\nInformation a...   \n",
       "83      83  5407int52.rtf  \\nDate of Interview: 08/01/02\\n\\nInformation a...   \n",
       "84      84  5407int53.rtf  \\nDate of Interview: 21/01/02\\n\\nInformation a...   \n",
       "85      85  5407int54.rtf  \\nDate of Interview: 17/01/02\\n\\nInformation a...   \n",
       "86      86  5407int55.rtf  \\nDate of Interview: 27/02/02\\n\\nInformation a...   \n",
       "\n",
       "   Occupation  \n",
       "46    Group 6  \n",
       "47    Group 6  \n",
       "48    Group 6  \n",
       "49    Group 6  \n",
       "50    Group 5  \n",
       "51    Group 5  \n",
       "52    Group 5  \n",
       "53    Group 5  \n",
       "54    Group 5  \n",
       "55    Group 5  \n",
       "56    Group 5  \n",
       "57    Group 5  \n",
       "58    Group 4  \n",
       "59    Group 4  \n",
       "60    Group 4  \n",
       "61    Group 4  \n",
       "62    Group 4  \n",
       "63    Group 4  \n",
       "64    Group 4  \n",
       "65    Group 3  \n",
       "66    Group 3  \n",
       "67    Group 3  \n",
       "68    Group 3  \n",
       "69    Group 3  \n",
       "70    Group 3  \n",
       "71    Group 3  \n",
       "72    Group 3  \n",
       "73    Group 2  \n",
       "74    Group 2  \n",
       "75    Group 2  \n",
       "76    Group 2  \n",
       "77    Group 2  \n",
       "78    Group 2  \n",
       "79    Group 4  \n",
       "80    Group 1  \n",
       "81    Group 1  \n",
       "82    Group 1  \n",
       "83    Group 1  \n",
       "84    Group 1  \n",
       "85    Group 1  \n",
       "86    Group 5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_file[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now let's move on to some data exploration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular conditional filtering vs Boolean masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will be using Regular conditional filtering and Boolean Masking to see if there are any missing values in the Occupation column.\n",
    "\n",
    "These methods are merely another way to filter your dataframe and inspect values that interest you.\n",
    "\n",
    "Neither method is superior, although boolean masking is said to be faster than regular filtering. \n",
    "\n",
    "Let's say we want to inspect the NaN values in the Occupation column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Number, Filename, everything_else, Occupation]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular conditional filtering often looks like this...\n",
    "\n",
    "oc_foot_mouth[oc_foot_mouth['Occupation'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay there are none - perfect! But can also double check this using Boolean masking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "      ...  \n",
       "82    False\n",
       "83    False\n",
       "84    False\n",
       "85    False\n",
       "86    False\n",
       "Name: Occupation, Length: 87, dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But, we can do the same thing by creating a boolean mask...\n",
    "\n",
    "missing = oc_foot_mouth['Occupation'].isna()\n",
    "\n",
    "# If we inspect this mask, we can see that it has returned a series of True/False values based on the condition\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Number, Filename, everything_else, Occupation]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can filter our dataframe with this boolean series\n",
    "# This will return the rows in which the condition = True\n",
    "\n",
    "oc_foot_mouth[missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oc_foot_mouth[missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>5407fg01.rtf</td>\n",
       "      <td>\\nGroups Discussion with Members of  Farmers F...</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>5407fg02.rtf</td>\n",
       "      <td>Groups Discussion with Members of Small Busine...</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>5407fg03.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Members of  Agricul...</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>5407fg04.rtf</td>\n",
       "      <td>\\nNO AUDIO RECORDING\\n\\nGroups Discussion with...</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>5407fg05.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Community Group of ...</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number      Filename                                    everything_else  \\\n",
       "40      40  5407fg01.rtf  \\nGroups Discussion with Members of  Farmers F...   \n",
       "41      41  5407fg02.rtf  Groups Discussion with Members of Small Busine...   \n",
       "42      42  5407fg03.rtf  \\n\\nGroups Discussion with Members of  Agricul...   \n",
       "43      43  5407fg04.rtf  \\nNO AUDIO RECORDING\\n\\nGroups Discussion with...   \n",
       "44      44  5407fg05.rtf  \\n\\nGroups Discussion with Community Group of ...   \n",
       "\n",
       "   Occupation  \n",
       "40    Group 1  \n",
       "41    Group 2  \n",
       "42    Group 3  \n",
       "43    Group 4  \n",
       "44    Group 5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup! Still nothing! Ok so now lets get onto seeing how many files there are for each occupation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tilde operator + boolean masking for counting Occupation instances\n",
    "\n",
    "Another filtering tip which is quite useful, is learning how to use the '~' tilde operator.\n",
    "This operator is used to negate the Boolean values in the dataframe, i.e., True becomes False and False becomes True!\n",
    "\n",
    "This can be quite useful. For instance, let's say we wanted to filter our dataframe by Occupation, but we want to look at every group apart from Group 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>25th February 2002</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5407diary10.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1937...</td>\n",
       "      <td>11th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5407diary13.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1947...</td>\n",
       "      <td>18th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5407diary14.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5407diary15.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1949...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>5407int49.rtf</td>\n",
       "      <td>\\nDate of Interview: 22/01/02\\n\\nInformation a...</td>\n",
       "      <td>22/01/02</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>5407int52.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/01/02\\n\\nInformation a...</td>\n",
       "      <td>08/01/02</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>5407int53.rtf</td>\n",
       "      <td>\\nDate of Interview: 21/01/02\\n\\nInformation a...</td>\n",
       "      <td>21/01/02</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>5407int54.rtf</td>\n",
       "      <td>\\nDate of Interview: 17/01/02\\n\\nInformation a...</td>\n",
       "      <td>17/01/02</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>5407int55.rtf</td>\n",
       "      <td>\\nDate of Interview: 27/02/02\\n\\nInformation a...</td>\n",
       "      <td>27/02/02</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number         Filename  \\\n",
       "4        4  5407diary09.rtf   \n",
       "5        5  5407diary10.rtf   \n",
       "6        6  5407diary13.rtf   \n",
       "7        7  5407diary14.rtf   \n",
       "8        8  5407diary15.rtf   \n",
       "..     ...              ...   \n",
       "82      82    5407int49.rtf   \n",
       "83      83    5407int52.rtf   \n",
       "84      84    5407int53.rtf   \n",
       "85      85    5407int54.rtf   \n",
       "86      86    5407int55.rtf   \n",
       "\n",
       "                                      everything_else               Dates  \\\n",
       "4   Information about diarist\\nDate of birth: 1981...  25th February 2002   \n",
       "5   Information about diarist\\nDate of birth: 1937...     11th March 2002   \n",
       "6   Information about diarist\\nDate of birth: 1947...     18th March 2002   \n",
       "7   \\nInformation about diarist\\nDate of birth: 19...                 NaN   \n",
       "8   Information about diarist\\nDate of birth: 1949...                 NaN   \n",
       "..                                                ...                 ...   \n",
       "82  \\nDate of Interview: 22/01/02\\n\\nInformation a...            22/01/02   \n",
       "83  \\nDate of Interview: 08/01/02\\n\\nInformation a...            08/01/02   \n",
       "84  \\nDate of Interview: 21/01/02\\n\\nInformation a...            21/01/02   \n",
       "85  \\nDate of Interview: 17/01/02\\n\\nInformation a...            17/01/02   \n",
       "86  \\nDate of Interview: 27/02/02\\n\\nInformation a...            27/02/02   \n",
       "\n",
       "   Gender Occupation  \n",
       "4       F    Group 5  \n",
       "5       M    Group 5  \n",
       "6       M    Group 5  \n",
       "7       F    Group 5  \n",
       "8       F    Group 5  \n",
       "..    ...        ...  \n",
       "82      F    Group 1  \n",
       "83      M    Group 1  \n",
       "84      M    Group 1  \n",
       "85      M    Group 1  \n",
       "86      F    Group 5  \n",
       "\n",
       "[78 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our instinct might be to do something like this...\n",
    "\n",
    "groups = ['Group 1', 'Group 2', 'Group 3', 'Group 4', 'Group 5']\n",
    "\n",
    "base_foot_mouth[base_foot_mouth['Occupation'].isin(groups)]\n",
    "\n",
    "\n",
    "# The isin() method is another way of applying multiple conditions for filtering\n",
    "\n",
    "# However, this is a bit laborious.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I will try to just use the == operator and see if that will work easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: 1975\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\nDiary 1         \\nThursday Meeting @ N Lakes\\nFriday TB testing on restocking farm. Usual chat and DEFRA comments\\nThe meeting (research panel gp 6) at the North Lakes was interesting. It surprises me sometimes how people (myself included) never seem to tire of the same stories and complaints over how the crisis was handled. Some of the episodes recounted must have been told dozens of times over the last year but whoever says it always seems just as keen to say it again  Perhaps a reflection of how deeply people feel about the events of the last year. Having said that, most of the resentments and rants that I hear on daily farm visits are focused fairly and squarely at DEFRA and not FMD virus. Farmers seem far more upset at the constriction put on them by DEFRA than they do by the loss of stock now, although I know and saw how utterly devastated most were when ...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\n\\nDiary 1\\nMonday was the usual long hard grind. I accept that I have to put in 10  12 hours and I dont mind doing the work because its not physically or mentally taxing but I do hate not having a lunch break, just that little bit of selfish time to site, have a cigarette, take the dogs down the river, see the horseswhatever. I do resent that fact that W (one of the bosses) almost always gets a lunch hour. B (the other boss) has gone up tremendously in my opinion for the way that he gets on with the work. He starts early, finishes late, hates DERFA paperwork and rarely complains. It is definitely grinding them down because they work like that at least 4 days a week. It has been a huge advantage this last year being part-time at work. My days off obviously arent my own as they used to be, but I do get away from the phone and the demands of clients. Some of our c...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: 1964\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\n\\nWeek beginning 4th March 02\\n\\nMonday 4th March\\nWe decided we now need more staff, a new vet and a part time receptionist, this could take us back up to our previous staffing level pre FM, bar a vet.  But this was probably going to be all the recruitments we would make this year.  Its a good sign As Things begin to get back to normal!!  Work is increasing quite a lot now most of our farmers have restocked, although a lot of them and us are still concerned about the future.\\nTuesday 5th March\\nA difficult day today with licences, two of our farmers needed Sole Occupancy Authentitys (SOA) and there were queries with their land, unless some of their fields could be redefined, they were worried their stock would suffer.  During the FM these worries have shown how much they care about their stock and find it very frustrating when they dont understand why we can...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\nSaturday 9th March 2002\\nAn old African proverb states, \"The best time to plant a tree was 20 years ago. The next best time is now.\"\\nI should have started this diary over a year ago to keep track of changes in the unrolling of the FMD epidemic and my feelings towards it. Today is probably a good day to start the diary as I was about to sit down after a really bad week to write some comments for the lessons learned inquiry and thought I should check the web site for an update. I found out to my considerable annoyance that the inquiry was coming to Cumbria to meet with DEFRA and hold the open meeting on Tuesday night, and if you wanted a ticket to attend, then you had to apply by a week ago. The overall impression is that the govt do not want to learn lessons. I was looking after kids as [wife] was on counselling course and I was on call Sat morn. The vets were busy ...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>5407fg06.rtf</td>\n",
       "      <td>\\n\\nGroup Discussion Panel Members, Group 6  Animal and Human Health related occupations  28/02/02\\n\\n7 Panel Members were present and they are identified thus:\\nL S T G M D Ly\\nWomen L T G M Ly\\nMen       S  D\\n\\n(  )\\tBracket with number in indicates missing word/words\\n[  ]\\tSquare bracket indicates action\\n\\nPoor recording constant background noise.  Was difficult to identify certain speakers as they had soft voices or they were sitting away from mike.\\n\\nSo if anybody can remember back to February when you first heard that Foot &amp; Mouth was diagnosed and the thoughts that were going through your head at that time.\\n\\nL I was so shocked it was just a big boggy of a disease that was never gonna happen in Britain.\\n\\nS Something that youd had [over talking] occasional 20 minute lecture on,  dont know what it looks like but I not likely to see it see it.  \\n\\nL If ever went abroad I mightnt have known about it.\\n\\nS Even when it came, I remember, sounds really a thing that eve...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>5407int02.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1975\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nThere is sensitive information on pages 35 and 36 of this transcript, which should not be used in any way that could identify the respondent\\n\\nInterview was held at the respondents home, a large terraced house near the centre of town. We sat at the kitchen table. Respondent seemed relaxed, happy to talk . I had rearranged the time of this interview so that I could attend the Anderson Inquiry meeting in Carlisle 2 days earlier. He had asked me about the meeting and I told him that people had noted inconsistencies in the way vets handled signing off procedures. He was explaining possible reasons for this when we switched on the tape:\\n\\nCos youre not, best not break the rules but sort of bend them to, say well, I know you Ive known you for the last three years and my boss has known you for the last twenty years, I know your ...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>5407int03.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1966\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nTape starts part way through a conversation about the start of FMD\\n\\nyeah, its like other people say its a long, long away is Essex you know its somewhere where Ive never been.  And you think well its come from a pig farm, so until you found out where the pig had come from you didnt really know where it was gonna have the focus you know.\\n\\nDo pigs carry more FMD virus?\\n\\nPigs excrete more virus yeah, they excrete more virus per breath, they are also quite susceptible to aerosol infection as are cattle, because they have a big lung volume.  Sheep are not as susceptible because they dont take in as much air with every breath.  \\n\\nBut then when it started to get up north and we had Longtown.  I mean, I come from a village thats about 15 miles north of Longtown, so I knew about Longtown Auction Mart. I used to take sheep the...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>5407int07.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1964\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nI arrived by taxi as the family car was unavailable and walked through the reception area.  L held open the door to her kitchen, \"come on in\" where her golden retriever made a fuss of me. \"We'll go through to the dining room\" - so we settled in one of the rooms looking over the A road  and beyond to rolling pastures. L's 15 year old daughter popped in , \"What's for tea then\" and the phone which rang in the background must have been picked up by someone in a different part of the house. We settled at the round table and started the tape.\\n\\nWhere I usually start is by asking you to tell me a little bit about you, your background and your family.\\n\\nWe bought the practice about twelve years ago now, with my hubbie the vet, and one daughter, and the dog.  Only one dog is ours, the other is somebody elses.   Me and G met when we both...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>5407int08.rtf</td>\n",
       "      <td>\\nDate of Interview: 06/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1963\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nI drove into the car-park of the modern veterinary practice.  The receptionist warned me that M had been called out on an emergency so I waited 40 minutes or so. M greeted me warmly and took me to a meeting-sized room upstairs that was dominated by a large table with chairs and shelves of text-books and manuals.  We moved into an adjacent small kitchen to make tea and then settled down with the tape switched on. \\n\\nCan you tell me a little bit about yourself and your background?\\n\\nBorn in Sheffield, brought up south of England, studied at Edinburgh University, got married, worked in N as a mixed practice for two years, and Ive been working here in Cumbria since [then].  Im married with four children.\\n\\nAnd why Cumbria?\\n\\nI wanted to do dairy practice.  I spent quite a long time in the last six months when I was at N working ...</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number         Filename  \\\n",
       "0        0  5407diary02.rtf   \n",
       "1        1  5407diary03.rtf   \n",
       "2        2  5407diary07.rtf   \n",
       "3        3  5407diary08.rtf   \n",
       "45      45     5407fg06.rtf   \n",
       "46      46    5407int02.rtf   \n",
       "47      47    5407int03.rtf   \n",
       "48      48    5407int07.rtf   \n",
       "49      49    5407int08.rtf   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            everything_else  \\\n",
       "0   \\n\\nInformation about diarist\\nDate of birth: 1975\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\nDiary 1         \\nThursday Meeting @ N Lakes\\nFriday TB testing on restocking farm. Usual chat and DEFRA comments\\nThe meeting (research panel gp 6) at the North Lakes was interesting. It surprises me sometimes how people (myself included) never seem to tire of the same stories and complaints over how the crisis was handled. Some of the episodes recounted must have been told dozens of times over the last year but whoever says it always seems just as keen to say it again  Perhaps a reflection of how deeply people feel about the events of the last year. Having said that, most of the resentments and rants that I hear on daily farm visits are focused fairly and squarely at DEFRA and not FMD virus. Farmers seem far more upset at the constriction put on them by DEFRA than they do by the loss of stock now, although I know and saw how utterly devastated most were when ...   \n",
       "1   Information about diarist\\nDate of birth: 1966\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\n\\nDiary 1\\nMonday was the usual long hard grind. I accept that I have to put in 10  12 hours and I dont mind doing the work because its not physically or mentally taxing but I do hate not having a lunch break, just that little bit of selfish time to site, have a cigarette, take the dogs down the river, see the horseswhatever. I do resent that fact that W (one of the bosses) almost always gets a lunch hour. B (the other boss) has gone up tremendously in my opinion for the way that he gets on with the work. He starts early, finishes late, hates DERFA paperwork and rarely complains. It is definitely grinding them down because they work like that at least 4 days a week. It has been a huge advantage this last year being part-time at work. My days off obviously arent my own as they used to be, but I do get away from the phone and the demands of clients. Some of our c...   \n",
       "2   \\n\\nInformation about diarist\\nDate of birth: 1964\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\n\\nWeek beginning 4th March 02\\n\\nMonday 4th March\\nWe decided we now need more staff, a new vet and a part time receptionist, this could take us back up to our previous staffing level pre FM, bar a vet.  But this was probably going to be all the recruitments we would make this year.  Its a good sign As Things begin to get back to normal!!  Work is increasing quite a lot now most of our farmers have restocked, although a lot of them and us are still concerned about the future.\\nTuesday 5th March\\nA difficult day today with licences, two of our farmers needed Sole Occupancy Authentitys (SOA) and there were queries with their land, unless some of their fields could be redefined, they were worried their stock would suffer.  During the FM these worries have shown how much they care about their stock and find it very frustrating when they dont understand why we can...   \n",
       "3   Information about diarist\\nDate of birth: 1963\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\n\\nSaturday 9th March 2002\\nAn old African proverb states, \"The best time to plant a tree was 20 years ago. The next best time is now.\"\\nI should have started this diary over a year ago to keep track of changes in the unrolling of the FMD epidemic and my feelings towards it. Today is probably a good day to start the diary as I was about to sit down after a really bad week to write some comments for the lessons learned inquiry and thought I should check the web site for an update. I found out to my considerable annoyance that the inquiry was coming to Cumbria to meet with DEFRA and hold the open meeting on Tuesday night, and if you wanted a ticket to attend, then you had to apply by a week ago. The overall impression is that the govt do not want to learn lessons. I was looking after kids as [wife] was on counselling course and I was on call Sat morn. The vets were busy ...   \n",
       "45  \\n\\nGroup Discussion Panel Members, Group 6  Animal and Human Health related occupations  28/02/02\\n\\n7 Panel Members were present and they are identified thus:\\nL S T G M D Ly\\nWomen L T G M Ly\\nMen       S  D\\n\\n(  )\\tBracket with number in indicates missing word/words\\n[  ]\\tSquare bracket indicates action\\n\\nPoor recording constant background noise.  Was difficult to identify certain speakers as they had soft voices or they were sitting away from mike.\\n\\nSo if anybody can remember back to February when you first heard that Foot & Mouth was diagnosed and the thoughts that were going through your head at that time.\\n\\nL I was so shocked it was just a big boggy of a disease that was never gonna happen in Britain.\\n\\nS Something that youd had [over talking] occasional 20 minute lecture on,  dont know what it looks like but I not likely to see it see it.  \\n\\nL If ever went abroad I mightnt have known about it.\\n\\nS Even when it came, I remember, sounds really a thing that eve...   \n",
       "46  \\nDate of Interview: 14/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1975\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nThere is sensitive information on pages 35 and 36 of this transcript, which should not be used in any way that could identify the respondent\\n\\nInterview was held at the respondents home, a large terraced house near the centre of town. We sat at the kitchen table. Respondent seemed relaxed, happy to talk . I had rearranged the time of this interview so that I could attend the Anderson Inquiry meeting in Carlisle 2 days earlier. He had asked me about the meeting and I told him that people had noted inconsistencies in the way vets handled signing off procedures. He was explaining possible reasons for this when we switched on the tape:\\n\\nCos youre not, best not break the rules but sort of bend them to, say well, I know you Ive known you for the last three years and my boss has known you for the last twenty years, I know your ...   \n",
       "47  \\nDate of Interview: 08/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1966\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nTape starts part way through a conversation about the start of FMD\\n\\nyeah, its like other people say its a long, long away is Essex you know its somewhere where Ive never been.  And you think well its come from a pig farm, so until you found out where the pig had come from you didnt really know where it was gonna have the focus you know.\\n\\nDo pigs carry more FMD virus?\\n\\nPigs excrete more virus yeah, they excrete more virus per breath, they are also quite susceptible to aerosol infection as are cattle, because they have a big lung volume.  Sheep are not as susceptible because they dont take in as much air with every breath.  \\n\\nBut then when it started to get up north and we had Longtown.  I mean, I come from a village thats about 15 miles north of Longtown, so I knew about Longtown Auction Mart. I used to take sheep the...   \n",
       "48  \\nDate of Interview: 14/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1964\\nGender: F\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nI arrived by taxi as the family car was unavailable and walked through the reception area.  L held open the door to her kitchen, \"come on in\" where her golden retriever made a fuss of me. \"We'll go through to the dining room\" - so we settled in one of the rooms looking over the A road  and beyond to rolling pastures. L's 15 year old daughter popped in , \"What's for tea then\" and the phone which rang in the background must have been picked up by someone in a different part of the house. We settled at the round table and started the tape.\\n\\nWhere I usually start is by asking you to tell me a little bit about you, your background and your family.\\n\\nWe bought the practice about twelve years ago now, with my hubbie the vet, and one daughter, and the dog.  Only one dog is ours, the other is somebody elses.   Me and G met when we both...   \n",
       "49  \\nDate of Interview: 06/03/02\\n\\nInformation about Panel Member\\nDate of birth: 1963\\nGender: M\\nOccupation: Group 6\\nGeographic region: North Cumbria\\n\\nI drove into the car-park of the modern veterinary practice.  The receptionist warned me that M had been called out on an emergency so I waited 40 minutes or so. M greeted me warmly and took me to a meeting-sized room upstairs that was dominated by a large table with chairs and shelves of text-books and manuals.  We moved into an adjacent small kitchen to make tea and then settled down with the tape switched on. \\n\\nCan you tell me a little bit about yourself and your background?\\n\\nBorn in Sheffield, brought up south of England, studied at Edinburgh University, got married, worked in N as a mixed practice for two years, and Ive been working here in Cumbria since [then].  Im married with four children.\\n\\nAnd why Cumbria?\\n\\nI wanted to do dairy practice.  I spent quite a long time in the last six months when I was at N working ...   \n",
       "\n",
       "   Occupation  \n",
       "0     Group 6  \n",
       "1     Group 6  \n",
       "2     Group 6  \n",
       "3     Group 6  \n",
       "45    Group 6  \n",
       "46    Group 6  \n",
       "47    Group 6  \n",
       "48    Group 6  \n",
       "49    Group 6  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oc_foot_mouth[oc_foot_mouth['Occupation'] == 'Group 6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks about right! Now let's use this with the len() function to get the counts we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      " \n",
      "13\n",
      " \n",
      "17\n",
      " \n",
      "16\n",
      " \n",
      "19\n",
      " \n",
      "9\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(len(oc_foot_mouth[oc_foot_mouth['Occupation'] == 'Group 1']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(oc_foot_mouth[oc_foot_mouth['Occupation'] == 'Group 2']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(oc_foot_mouth[oc_foot_mouth['Occupation'] == 'Group 3']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(oc_foot_mouth[oc_foot_mouth['Occupation'] == 'Group 4']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(oc_foot_mouth[oc_foot_mouth['Occupation'] == 'Group 5']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(oc_foot_mouth[oc_foot_mouth['Occupation'] == 'Group 6']))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay os a bit of discrepancy in the sizes! Let's see if it has anything to do with a discrepancy in the respondants recorded for each type of data collection (diary vs group focus vs interview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " \n",
      "6\n",
      " \n",
      "8\n",
      " \n",
      "7\n",
      " \n",
      "9\n",
      " \n",
      "4\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(len(diary_file[diary_file['Occupation'] == 'Group 1']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(diary_file[diary_file['Occupation'] == 'Group 2']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(diary_file[diary_file['Occupation'] == 'Group 3']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(diary_file[diary_file['Occupation'] == 'Group 4']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(diary_file[diary_file['Occupation'] == 'Group 5']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(diary_file[diary_file['Occupation'] == 'Group 6']))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      " \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(len(group_file[group_file['Occupation'] == 'Group 1']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(group_file[group_file['Occupation'] == 'Group 2']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(group_file[group_file['Occupation'] == 'Group 3']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(group_file[group_file['Occupation'] == 'Group 4']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(group_file[group_file['Occupation'] == 'Group 5']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(group_file[group_file['Occupation'] == 'Group 6']))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " \n",
      "6\n",
      " \n",
      "8\n",
      " \n",
      "8\n",
      " \n",
      "9\n",
      " \n",
      "4\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(len(interview_file[interview_file['Occupation'] == 'Group 1']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(interview_file[interview_file['Occupation'] == 'Group 2']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(interview_file[interview_file['Occupation'] == 'Group 3']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(interview_file[interview_file['Occupation'] == 'Group 4']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(interview_file[interview_file['Occupation'] == 'Group 5']))\n",
    "print(\" \")\n",
    "\n",
    "print(len(interview_file[interview_file['Occupation'] == 'Group 6']))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so it looks like this discrepancy is the same across the formats! In which case we will definitely need to calculate one polarity average (preferably a mean result) for each of the occupations to account for this! I think if I were to plot multiple averages for each occupation the variance in occupation distribution might skew things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further resources\n",
    "\n",
    "If you want to know more about different ways of filtering dataframes, please visit the link below:\n",
    "\n",
    "* https://towardsdatascience.com/8-ways-to-filter-pandas-dataframes-d34ba585c1b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. One of the files in ./data is... foot_mouth_original.xls\n",
      "2. One of the files in ./data is... text.csv\n",
      "\n",
      " \n",
      "DataFrames Successfully split!\n"
     ]
    }
   ],
   "source": [
    "# EVERYTHING YOU NEED TO DOWNLOAD IF THINGS GO WRONG\n",
    "\n",
    "import os                         # os is a module for navigating your machine (e.g., file directories).\n",
    "import pandas as pd\n",
    "\n",
    "# List all of the files in the \"data\" folder that is provided to you\n",
    "print(\"\")\n",
    "for file in os.listdir(\"./data/foot_mouth\"):\n",
    "   print(\"2. One of the files in ./data is...\", file)\n",
    "print(\"\")\n",
    "\n",
    "# Renaming Columns\n",
    "foot_mouth_df = pd.read_csv ('../code/data/foot_mouth/text.csv') \n",
    "\n",
    "foot_mouth_df.columns = [\"Number\", \"Filename\", \"everything_else\"]\n",
    "foot_mouth_df.head()\n",
    "print(\" \")\n",
    "\n",
    "#Creating New Dataframe with Occupation Column\n",
    "oc_foot_mouth = foot_mouth_df.assign(Occupation = foot_mouth_df['everything_else'].str.extract(r'(\\w+\\s+\\d{1,2})'))\n",
    "\n",
    "oc_foot_mouth.head() # checking if it worked!\n",
    "\n",
    "# Splitting DataFrames\n",
    "diary_file = oc_foot_mouth.loc[:39]     # Saving variable for all diary rows\n",
    "group_file = oc_foot_mouth.loc[40:45]   # Saving variables for all group rows\n",
    "interview_file = oc_foot_mouth.loc[46:] # Saving variable for all interview rows\n",
    "\n",
    "print(\"DataFrames Successfully split!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about RegEx patterns (this one took me a while to figure out, so I clearly need to read up on them!) I suggest the following resources:\n",
    "\n",
    "* https://www.dataquest.io/blog/regular-expressions-data-scientists/\n",
    "* https://stackoverflow.com/questions/71499365/how-to-extract-date-in-month-d-yr-format-using-regex (for easier to copy/paste date formatting)\n",
    "\n",
    "This is also a useful resource if you want to test your RegEx expressions:\n",
    "\n",
    "* https://regex101.com - I used it to help figure out why my regex date pattern wasn't working"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
